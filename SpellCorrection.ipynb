{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f7d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab18a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\GPT\n",
      "[nltk_data]     BANTWAL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "correct_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730b75a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "amazing\n",
      "intelligent\n"
     ]
    }
   ],
   "source": [
    "incorrect_words=['happpy', 'amzzzzzzaing', 'intelliengt']\n",
    "for word in incorrect_words:\n",
    "    temp = [(edit_distance(word, w),w) for w in correct_words if w[0]==word[0]]\n",
    "    print(sorted(temp, key = lambda val:val[0])[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55bba29",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8a63be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural language processing refers to the branch of computer science and more specifically the branch of artificial intelligence or ai concerned with giving computers the ability to understand text and spoken words in much the same way human beings can nlp combines computational linguistics with statistical machine learning and deep learning models together these technologies enable computers to process human language in the form of text or voice data and to understand its full meaning complete with the speaker or writer s intent and sentiment\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "file = open(\"nlp.txt\", \"r\")\n",
    "text = file.read()\n",
    "text =text.lower()\n",
    "import re\n",
    "text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "text = re.sub(\"\\S*\\d\\S*\", \"\", text).strip()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c20b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', 'refers', 'to', 'the', 'branch', 'of', 'computer', 'science', 'and', 'more', 'specifically', 'the', 'branch', 'of', 'artificial', 'intelligence', 'or', 'ai', 'concerned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'understand', 'text', 'and', 'spoken', 'words', 'in', 'much', 'the', 'same', 'way', 'human', 'beings', 'can', 'nlp', 'combines', 'computational', 'linguistics', 'with', 'statistical', 'machine', 'learning', 'and', 'deep', 'learning', 'models', 'together', 'these', 'technologies', 'enable', 'computers', 'to', 'process', 'human', 'language', 'in', 'the', 'form', 'of', 'text', 'or', 'voice', 'data', 'and', 'to', 'understand', 'its', 'full', 'meaning', 'complete', 'with', 'the', 'speaker', 'or', 'writer', 's', 'intent', 'and', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text,preserve_line=True)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11fd88ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', 'refer', 'to', 'the', 'branch', 'of', 'comput', 'scienc', 'and', 'more', 'specif', 'the', 'branch', 'of', 'artifici', 'intellig', 'or', 'ai', 'concern', 'with', 'give', 'comput', 'the', 'abil', 'to', 'understand', 'text', 'and', 'spoken', 'word', 'in', 'much', 'the', 'same', 'way', 'human', 'be', 'can', 'nlp', 'combin', 'comput', 'linguist', 'with', 'statist', 'machin', 'learn', 'and', 'deep', 'learn', 'model', 'togeth', 'these', 'technolog', 'enabl', 'comput', 'to', 'process', 'human', 'languag', 'in', 'the', 'form', 'of', 'text', 'or', 'voic', 'data', 'and', 'to', 'understand', 'it', 'full', 'mean', 'complet', 'with', 'the', 'speaker', 'or', 'writer', 's', 'intent', 'and', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps_stem_sent = [ps.stem(words_sent) for words_sent in words]\n",
    "print(ps_stem_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d6851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', 'refer', 'to', 'the', 'branch', 'of', 'comput', 'scienc', 'and', 'more', 'specif', 'the', 'branch', 'of', 'artifici', 'intellig', 'or', 'ai', 'concern', 'with', 'give', 'comput', 'the', 'abil', 'to', 'understand', 'text', 'and', 'spoken', 'word', 'in', 'much', 'the', 'same', 'way', 'human', 'be', 'can', 'nlp', 'combin', 'comput', 'linguist', 'with', 'statist', 'machin', 'learn', 'and', 'deep', 'learn', 'model', 'togeth', 'these', 'technolog', 'enabl', 'comput', 'to', 'process', 'human', 'languag', 'in', 'the', 'form', 'of', 'text', 'or', 'voic', 'data', 'and', 'to', 'understand', 'it', 'full', 'mean', 'complet', 'with', 'the', 'speaker', 'or', 'writer', 's', 'intent', 'and', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "ss = SnowballStemmer(language='english')\n",
    "ss_stems = [ss.stem(words_sent) for words_sent in words]\n",
    "print(ss_stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0758d",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "281f61f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', 'refers', 'to', 'the', 'branch', 'of', 'computer', 'science', 'and', 'more', 'specifically', 'the', 'branch', 'of', 'artificial', 'intelligence', 'or', 'ai', 'concerned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'understand', 'text', 'and', 'spoken', 'words', 'in', 'much', 'the', 'same', 'way', 'human', 'beings', 'can', 'nlp', 'combines', 'computational', 'linguistics', 'with', 'statistical', 'machine', 'learning', 'and', 'deep', 'learning', 'models', 'together', 'these', 'technologies', 'enable', 'computers', 'to', 'process', 'human', 'language', 'in', 'the', 'form', 'of', 'text', 'or', 'voice', 'data', 'and', 'to', 'understand', 'its', 'full', 'meaning', 'complete', 'with', 'the', 'speaker', 'or', 'writer', 's', 'intent', 'and', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc653512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', 'refers', 'to', 'the', 'branch', 'of', 'computer', 'science', 'and', 'more', 'specifically', 'the', 'branch', 'of', 'artificial', 'intelligence', 'or', 'ai', 'concerned', 'with', 'giving', 'computer', 'the', 'ability', 'to', 'understand', 'text', 'and', 'spoken', 'word', 'in', 'much', 'the', 'same', 'way', 'human', 'being', 'can', 'nlp', 'combine', 'computational', 'linguistics', 'with', 'statistical', 'machine', 'learning', 'and', 'deep', 'learning', 'model', 'together', 'these', 'technology', 'enable', 'computer', 'to', 'process', 'human', 'language', 'in', 'the', 'form', 'of', 'text', 'or', 'voice', 'data', 'and', 'to', 'understand', 'it', 'full', 'meaning', 'complete', 'with', 'the', 'speaker', 'or', 'writer', 's', 'intent', 'and', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lem_sent = [lemmatizer.lemmatize(words_sent) for words_sent in words]\n",
    "print(lem_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da96aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "  \n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad8df2",
   "metadata": {},
   "source": [
    "# Parts of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a578312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e2482af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech:  [('I', 'PRP'), ('am', 'VBP'), ('very', 'RB'), ('hungry', 'JJ'), ('but', 'CC'), ('the', 'DT'), ('fridge', 'NN'), ('is', 'VBZ'), ('empty', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "text = 'I am very hungry but the fridge is empty'\n",
    "words = word_tokenize(text)\n",
    "print(\"Parts of Speech: \",nltk.pos_tag(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025fb61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
